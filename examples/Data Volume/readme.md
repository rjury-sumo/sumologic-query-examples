# Data Volume
## Sumo Logic App For: Data Volume
The Data Volume App provides you with summary and detailed views of your account's data usage volume by data type, tier, category, collector, source name, and hosts via predefined searches and dashboards. Before you can install and use the Data Volume app, an administrator must first enable the feature.
Docs Link: [Data Volume](https://help.sumologic.com/?cid=21017)

## Searches

### Log Searches

- **Actual (Average) DPM Ingested**: from Dashboard: Data Volume/Data Volume - Capacity Utilization 
- **Actual (Average) DPM Ingested**: from Dashboard: Installed Apps/Data Volume/Data Volume - Capacity Utilization 
- **Actual (Average) Log Ingested**: from Dashboard: Data Volume/Data Volume - Capacity Utilization 
- **Actual (Average) Log Ingested**: from Dashboard: Installed Apps/Data Volume/Data Volume - Capacity Utilization 
- **Average Daily Ingest**: from Dashboard: Data Volume/Data Volume - Logs 
- **Average Daily Ingest**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Candidate Partitions**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Candidate Partitions**: from Dashboard: Data Volume/Data Volume - Logs 
- **Continuous Tier**: from Dashboard: Data Volume/Data Volume - Credits 
- **Credits Usage Trend**: from Dashboard: Data Volume/Data Volume - Credits 
- **CSE Tier**: from Dashboard: Data Volume/Data Volume - Credits 
- **Daily Ingest (GB)**: from Dashboard: Data Volume/Data Volume - Logs 
- **Daily Ingest (GB)**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Daily Ingest Vs Average Daily Ingest Capacity**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Daily Ingest Vs Average Daily Ingest Capacity**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Daily Ingest Vs Ingest Capacity**: from Dashboard: Data Volume/Data Volume - Logs 
- **Daily Ingest Vs Ingest Capacity**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Data Ingest Outlier**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Data Ingest Outlier**: from Dashboard: Data Volume/Data Volume - Logs 
- **Data Ingest Prediction**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Data Ingest Prediction**: from Dashboard: Data Volume/Data Volume - Logs 
- **Data Volume Outliers**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Data Volume Outliers**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Data Volume Predictions**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Data Volume Predictions**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Days when Ingestion Exceeded Capacity**: from Dashboard: Data Volume/Data Volume - Logs 
- **Days When Ingestion Exceeded Capacity**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Days when Ingestion Exceeded Capacity**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Days When Ingestion Exceeded Capacity**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Default Index**: from Dashboard: Data Volume/Data Volume - Logs 
- **Default Index**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **DPM Ingest Capacity Utilization**: from Dashboard: Data Volume/Data Volume - Capacity Utilization 
- **DPM Ingest Capacity Utilization**: from Dashboard: Installed Apps/Data Volume/Data Volume - Capacity Utilization 
- **Frequent Tier**: from Dashboard: Data Volume/Data Volume - Credits 
- **Index Volume Trend**: from Dashboard: Data Volume/Data Volume - Logs 
- **Index Volume Trend**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Infrequent Tier**: from Dashboard: Data Volume/Data Volume - Credits 
- **Ingest - {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Ingest - {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Ingest - {{Unit}} per minute**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Ingest - {{Unit}} per minute**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Ingest - DataPoints**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Ingest - DataPoints**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Ingest - LogsToMetricsRuleName**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Ingest - LogsToMetricsRuleName**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Ingest {{LogView}} - GB/Day**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Ingest {{LogView}} - GB/Day**: from Dashboard: Data Volume/Data Volume - Overview 
- **Ingest {{LogView}}- Log Volume**: from Dashboard: Data Volume/Data Volume - Overview 
- **Ingest {{LogView}}- Log Volume**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Ingest {{MetricsView}}- Data Points**: from Dashboard: Data Volume/Data Volume - Overview 
- **Ingest {{MetricsView}}- Data Points**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Ingest {{MetricsView}}- DPM**: from Dashboard: Data Volume/Data Volume - Overview 
- **Ingest {{MetricsView}}- DPM**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Ingest {{TracingView}}- Billed Bytes**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Ingest {{TracingView}}- Billed Bytes**: from Dashboard: Data Volume/Data Volume - Overview 
- **Ingest {{TracingView}}- Billed GBytes per min**: from Dashboard: Data Volume/Data Volume - Overview 
- **Ingest {{TracingView}}- Billed GBytes per min**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Ingest by Collector**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields 
- **Ingest by Source Category**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields 
- **Ingest by Source Host**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields 
- **Ingest DPM**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Ingest DPM**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Ingest Outlier - {{MetricsView}}**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Ingest Outlier - {{MetricsView}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Ingest Outlier - {{TracingView}} by {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Ingest Outlier - {{TracingView}} by {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Ingest Prediction - {{MetricsView}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Ingest Prediction - {{MetricsView}}**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Ingest Prediction - {{TracingView}} by {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Ingest Prediction - {{TracingView}} by {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Ingest Predictions - {{Unit}} for Next Day**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Ingest Predictions - {{Unit}} for Next Day**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Ingest Spike  of Last {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Ingest Spike  of Last {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Ingest Spike (Last data point)**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Ingest Spike (Last data point)**: from Dashboard: Data Volume/Data Volume - Logs 
- **Ingest Spikes for Top 5 Collectors**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Ingest Spikes for Top 5 Collectors**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Ingest Spikes for Top 5 Source Categories**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Ingest Spikes for Top 5 Source Categories**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Ingest Spikes for Top 5 Source Hosts**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Ingest Spikes for Top 5 Source Hosts**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Ingest Spikes for Top 5 Source Names**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Ingest Spikes for Top 5 Source Names**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Ingest Spikes for Top 5 Sources**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Ingest Spikes for Top 5 Sources**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Ingest Today Vs Yesterday - {{MetricsView}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Ingest Today Vs Yesterday - {{MetricsView}}**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Ingest Today vs Yesterday - {{TracingView}}  by {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Ingest Today vs Yesterday - {{TracingView}}  by {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Ingest Trend - {{MetricsView}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Ingest Trend - {{MetricsView}}**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Ingest Trend - {{TracingView}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Ingest Trend - {{TracingView}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Log Ingest Capacity Utilization**: from Dashboard: Data Volume/Data Volume - Capacity Utilization 
- **Log Ingest Capacity Utilization**: from Dashboard: Installed Apps/Data Volume/Data Volume - Capacity Utilization 
- **Metrics Ingestion**: from Dashboard: Data Volume/Data Volume - Credits 
- **Predicted Ingest Tomorrow**: from Dashboard: Data Volume/Data Volume - Logs 
- **Predicted Ingest Tomorrow**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Predicted Ingest Tomorrow**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Predicted Ingest Tomorrow**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Source Category (1-30%) Vol**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Source Category (1-30%) Vol**: from Dashboard: Data Volume/Data Volume - Logs 
- **Source Category (30%+) Vol**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Source Category (30%+) Vol**: from Dashboard: Data Volume/Data Volume - Logs 
- **Subscribed DPM Ingest Capacity**: from Dashboard: Data Volume/Data Volume - Capacity Utilization 
- **Subscribed DPM Ingest Capacity**: from Dashboard: Installed Apps/Data Volume/Data Volume - Capacity Utilization 
- **Subscribed Log Ingest Capacity**: from Dashboard: Installed Apps/Data Volume/Data Volume - Capacity Utilization 
- **Subscribed Log Ingest Capacity**: from Dashboard: Data Volume/Data Volume - Capacity Utilization 
- **Top 10 {{LogView}} by Credits used in Continuous Tier**: from Dashboard: Data Volume/Data Volume - Credits 
- **Top 10 {{LogView}} by Credits used in CSE Tier**: from Dashboard: Data Volume/Data Volume - Credits 
- **Top 10 {{LogView}} by Credits used in Frequent Tier**: from Dashboard: Data Volume/Data Volume - Credits 
- **Top 10 {{LogView}} by Credits used in Infrequent Tier**: from Dashboard: Data Volume/Data Volume - Credits 
- **Top 10 {{MetricsView}} by Credits used in Metrics Ingestion**: from Dashboard: Data Volume/Data Volume - Credits 
- **Top 10 {{TracingView}} by Credits used in Tracing Ingestion**: from Dashboard: Data Volume/Data Volume - Credits 
- **Top 5  {{LogView}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Top 5  {{LogView}}**: from Dashboard: Data Volume/Data Volume - Overview 
- **Top 5 {{MetricsView}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Top 5 {{MetricsView}}**: from Dashboard: Data Volume/Data Volume - Overview 
- **Top 5 {{TracingView}} by Billed Bytes**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Top 5 {{TracingView}} by Billed Bytes**: from Dashboard: Data Volume/Data Volume - Overview 
- **Top 5 Collectors**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields 
- **Top 5 Collectors**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Top 5 Collectors**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Top 5 Collectors**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Top 5 Collectors**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Top 5 Collectors by {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Top 5 Collectors by {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Top 5 Indexes (Non-Default)**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Top 5 Indexes (Non-Default)**: from Dashboard: Data Volume/Data Volume - Logs 
- **Top 5 Service by {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Top 5 Service by {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Top 5 Source Categories**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Top 5 Source Categories**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Top 5 Source Categories**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Top 5 Source Categories**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Top 5 Source Categories**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields 
- **Top 5 Source Categories by {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Top 5 Source Categories by {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Top 5 Source Hosts**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Top 5 Source Hosts**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Top 5 Source Hosts**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Top 5 Source Hosts**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields 
- **Top 5 Source Hosts**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Top 5 source Hosts by {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Top 5 source Hosts by {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Top 5 source Name by {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Top 5 source Name by {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Top 5 Source Names**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Top 5 Source Names**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Top 5 Sources**: from Dashboard: Data Volume/Data Volume - Metrics 
- **Top 5 Sources**: from Dashboard: Installed Apps/Data Volume/Data Volume - Metrics 
- **Top 5 Sources**: from Dashboard: Installed Apps/Data Volume/Data Volume - Log Spikes 
- **Top 5 Sources**: from Dashboard: Data Volume/Data Volume - Log Spikes 
- **Top 5 Sources by {{Unit}}**: from Dashboard: Data Volume/Data Volume - Tracing 
- **Top 5 Sources by {{Unit}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Tracing 
- **Top Sources  (Other < {{other_pct}}%)**: from Dashboard: Data Volume/Data Volume - Credits 
- **Total Data Ingested**: from Dashboard: Installed Apps/Data Volume/Data Volume - Logs 
- **Total Data Ingested**: from Dashboard: Data Volume/Data Volume - Logs 
- **Tracing Ingestion by BilledBytes**: from Dashboard: Data Volume/Data Volume - Credits 
- **Usage Percentage of {{LogView}} by Tier**: from Dashboard: Data Volume/Data Volume - Overview 
- **Usage Percentage of {{LogView}} by Tier**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Usage Percentage of {{LogView}} by Tier({{Tier}})**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Usage Percentage of {{LogView}} by Tier({{Tier}})**: from Dashboard: Data Volume/Data Volume - Overview 
- **Usage Percentage of {{MetricsView}}**: from Dashboard: Data Volume/Data Volume - Overview 
- **Usage Percentage of {{MetricsView}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Usage Percentage of {{TracingView}}**: from Dashboard: Installed Apps/Data Volume/Data Volume - Overview 
- **Usage Percentage of {{TracingView}}**: from Dashboard: Data Volume/Data Volume - Overview

### Metric Searches


## Search Table

|app\_topic|search\_name|type|origin|search|
|:--|:--|:--|:--|:--|
|Data Volume|Actual (Average) DPM Ingested|Logs|Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as dpm <br />\| fields -datapoints, duration\_in\_min|
|Data Volume|Actual (Average) DPM Ingested|Logs|Installed Apps/Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as dpm <br />\| fields -datapoints, duration\_in\_min|
|Data Volume|Actual (Average) Log Ingested|Logs|Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume \_sourcecategory="collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as ingest\_gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| ingest\_gbytes / duration\_in\_day as %"AvgLogIngestPerDay"<br />\| fields %"AvgLogIngestPerDay"|
|Data Volume|Actual (Average) Log Ingested|Logs|Installed Apps/Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume \_sourcecategory="collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as ingest\_gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| ingest\_gbytes / duration\_in\_day as %"AvgLogIngestPerDay"<br />\| fields %"AvgLogIngestPerDay"|
|Data Volume|Average Daily Ingest|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| gbytes / duration\_in\_day as %"GB/Day"<br />\| fields %"GB/Day"<br /><br />|
|Data Volume|Average Daily Ingest|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| gbytes / duration\_in\_day as %"GB/Day"<br />\| fields %"GB/Day"<br /><br />|
|Data Volume|Candidate Partitions|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory="sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1d<br />\| sum(gbytes) as gbytes by \_timeslice, sourcecategory<br />\| total gbytes as tot\_gbytes by \_timeslice<br />\| (gbytes\*100/tot\_gbytes) as pct\_total <br />\| where pct\_total \>= 1 and pct\_total \<= 30 // candidates for partition<br />\| count by \_timeslice |
|Data Volume|Candidate Partitions|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory="sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1d<br />\| sum(gbytes) as gbytes by \_timeslice, sourcecategory<br />\| total gbytes as tot\_gbytes by \_timeslice<br />\| (gbytes\*100/tot\_gbytes) as pct\_total <br />\| where pct\_total \>= 1 and pct\_total \<= 30 // candidates for partition<br />\| count by \_timeslice |
|Data Volume|Continuous Tier|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "dataTier","sizeInBytes" as  dataTier, bytes<br />\|where dataTier matches "Continuous"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes <br />\| gbytes\*{{ContinuousTierBurndownRate}} as credits <br />\|fields -gbytes|
|Data Volume|Credits Usage Trend|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data  "dataTier","sizeInBytes" as  dataTier, bytes<br />\|where  dataTier matches "Frequent"<br />\|timeslice {{timeslice}}<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice,dataTier<br />\| gbytes\*{{FrequentTierBurndownRate}} as gbytes<br />\|transpose row \_timeslice  column dataTier|
|Data Volume|CSE Tier|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "dataTier","sizeInBytes" as  dataTier, bytes<br />\|where dataTier matches "CSE"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes <br />\| gbytes\*{{CSETierBurndownRate}} as credits <br />\|fields -gbytes|
|Data Volume|Daily Ingest (GB)|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1d<br />\| sum(gbytes) as gbytes by \_timeslice|
|Data Volume|Daily Ingest (GB)|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1d<br />\| sum(gbytes) as gbytes by \_timeslice|
|Data Volume|Daily Ingest Vs Average Daily Ingest Capacity|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 1d<br />\| sum(datapoints) as daily\_ingest\_datapoints by \_timeslice<br />\| {{Metric\_DPM\_Ingest\_Capacity}} as DPM\_Capacity // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| DPM\_Capacity \* 60 \* 24 as DataPoint\_Capacity // Set this calculated value through gear icon for "Colors by Value Range..."<br />\| fields -DPM\_Capacity|
|Data Volume|Daily Ingest Vs Average Daily Ingest Capacity|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 1d<br />\| sum(datapoints) as daily\_ingest\_datapoints by \_timeslice<br />\| {{Metric\_DPM\_Ingest\_Capacity}} as DPM\_Capacity // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| DPM\_Capacity \* 60 \* 24 as DataPoint\_Capacity // Set this calculated value through gear icon for "Colors by Value Range..."<br />\| fields -DPM\_Capacity|
|Data Volume|Daily Ingest Vs Ingest Capacity|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| timeslice 1d<br />\| sum(gbytes) as daily\_ingest\_gbytes by \_timeslice<br />\| {{Daily\_Log\_Ingest\_Capacity}} as daily\_log\_ingest\_capacity // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview. <br />|
|Data Volume|Daily Ingest Vs Ingest Capacity|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| timeslice 1d<br />\| sum(gbytes) as daily\_ingest\_gbytes by \_timeslice<br />\| {{Daily\_Log\_Ingest\_Capacity}} as daily\_log\_ingest\_capacity // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview. <br />|
|Data Volume|Data Ingest Outlier|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 6h<br />\| sum(gbytes) as gbytes by \_timeslice<br />\| outlier gbytes|
|Data Volume|Data Ingest Outlier|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 6h<br />\| sum(gbytes) as gbytes by \_timeslice<br />\| outlier gbytes|
|Data Volume|Data Ingest Prediction|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1h<br />\| sum(gbytes) as gbytes by \_timeslice<br />\| predict gbytes by 1h model=ar, forecast=20<br />\| fillmissing timeslice(1h)<br />\| fields - gbytes\_error|
|Data Volume|Data Ingest Prediction|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1h<br />\| sum(gbytes) as gbytes by \_timeslice<br />\| predict gbytes by 1h model=ar, forecast=20<br />\| fillmissing timeslice(1h)<br />\| fields - gbytes\_error|
|Data Volume|Data Volume Outliers|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where   dataTier matches "{{Tier}}"<br />\| timeslice 6h<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice<br />\| outlier gbytes|
|Data Volume|Data Volume Outliers|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where   dataTier matches "{{Tier}}"<br />\| timeslice 6h<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice<br />\| outlier gbytes|
|Data Volume|Data Volume Predictions|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1h<br />\| sum(gbytes) as gbytes by \_timeslice<br />\| predict gbytes by 1h model=ar, forecast=20<br />\| fillmissing timeslice(1h)<br />\| fields - gbytes\_error<br />|
|Data Volume|Data Volume Predictions|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1h<br />\| sum(gbytes) as gbytes by \_timeslice<br />\| predict gbytes by 1h model=ar, forecast=20<br />\| fillmissing timeslice(1h)<br />\| fields - gbytes\_error<br />|
|Data Volume|Days when Ingestion Exceeded Capacity|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume" <br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| timeslice 24h<br />\| sum(gbytes) as daily\_ingest\_gbytes by \_timeslice<br />\| where daily\_ingest\_gbytes\>{{Daily\_Log\_Ingest\_Capacity}}<br />\| count|
|Data Volume|Days When Ingestion Exceeded Capacity|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 24h<br />\| sum(datapoints) as datapoints by  \_timeslice<br />\| where datapoints\>{{Metric\_DPM\_Ingest\_Capacity}}\*60\*24<br />\| count<br /><br />|
|Data Volume|Days when Ingestion Exceeded Capacity|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume" <br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| timeslice 24h<br />\| sum(gbytes) as daily\_ingest\_gbytes by \_timeslice<br />\| where daily\_ingest\_gbytes\>{{Daily\_Log\_Ingest\_Capacity}}<br />\| count|
|Data Volume|Days When Ingestion Exceeded Capacity|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 24h<br />\| sum(datapoints) as datapoints by  \_timeslice<br />\| where datapoints\>{{Metric\_DPM\_Ingest\_Capacity}}\*60\*24<br />\| count<br /><br />|
|Data Volume|Default Index|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory="view\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as index, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| where index ="Default Index"<br />\| bytes/1Gi as gbytes<br />\| sum(gbytes) as gbytes by index<br />\| top 5 index by gbytes|
|Data Volume|Default Index|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory="view\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as index, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| where index ="Default Index"<br />\| bytes/1Gi as gbytes<br />\| sum(gbytes) as gbytes by index<br />\| top 5 index by gbytes|
|Data Volume|DPM Ingest Capacity Utilization|Logs|Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as dpm <br />\| {{Metric\_DPM\_Ingest\_Capacity}} as %"DPM\_Capacity" // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| (dpm/%"DPM\_Capacity")\*100 as %"DPM\_Capacity\_Utilization"<br />\| fields -datapoints, duration\_in\_min, dpm, %"DPM\_Capacity"|
|Data Volume|DPM Ingest Capacity Utilization|Logs|Installed Apps/Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as dpm <br />\| {{Metric\_DPM\_Ingest\_Capacity}} as %"DPM\_Capacity" // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| (dpm/%"DPM\_Capacity")\*100 as %"DPM\_Capacity\_Utilization"<br />\| fields -datapoints, duration\_in\_min, dpm, %"DPM\_Capacity"|
|Data Volume|Frequent Tier|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "dataTier","sizeInBytes" as  dataTier, bytes<br />\|where dataTier matches "Frequent"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes <br />\| gbytes\*{{FrequentTierBurndownRate}} as credits <br />\|fields -gbytes|
|Data Volume|Index Volume Trend|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume sizeInBytes  \_sourceCategory = "view\_and\_tier\_volume" <br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as view\_name, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| where view\_name not in ("sumologic\_volume", "sumologic\_audit")<br />\| bytes/1Gi as gbytes <br />\| timeslice 1d<br />\| sum(gbytes) as gbytes by \_timeslice, view\_name<br />\| transpose row \_timeslice column view\_name|
|Data Volume|Index Volume Trend|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume sizeInBytes  \_sourceCategory = "view\_and\_tier\_volume" <br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as view\_name, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| where view\_name not in ("sumologic\_volume", "sumologic\_audit")<br />\| bytes/1Gi as gbytes <br />\| timeslice 1d<br />\| sum(gbytes) as gbytes by \_timeslice, view\_name<br />\| transpose row \_timeslice column view\_name|
|Data Volume|Infrequent Tier|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "dataTier","sizeInBytes" as  dataTier, bytes<br />\|where dataTier matches "Infrequent"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes <br />\| gbytes\*{{InfrequentTierBurndownRate}} as credits <br />\|fields -gbytes|
|Data Volume|Ingest - {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as {{Unit}}<br />\|if("{{Unit}}" matches "spansCount", 1000\*1000, 1Gi) as denominator <br />\| {{Unit}}/denominator as  {{Unit}}<br />\| fields {{Unit}}<br /><br />|
|Data Volume|Ingest - {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as {{Unit}}<br />\|if("{{Unit}}" matches "spansCount", 1000\*1000, 1Gi) as denominator <br />\| {{Unit}}/denominator as  {{Unit}}<br />\| fields {{Unit}}<br /><br />|
|Data Volume|Ingest - {{Unit}} per minute|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as {{Unit}}<br />\|if("{{Unit}}" matches "spansCount", 1000000, 1Gi) as denominator <br />\| {{Unit}}/denominator as  {{Unit}}<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| {{Unit}}/duration\_in\_min as {{Unit}}<br />\| fields {{Unit}}<br />|
|Data Volume|Ingest - {{Unit}} per minute|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as {{Unit}}<br />\|if("{{Unit}}" matches "spansCount", 1000000, 1Gi) as denominator <br />\| {{Unit}}/denominator as  {{Unit}}<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| {{Unit}}/duration\_in\_min as {{Unit}}<br />\| fields {{Unit}}<br />|
|Data Volume|Ingest - DataPoints|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as ThousandDataPoints<br />\| fields ThousandDataPoints|
|Data Volume|Ingest - DataPoints|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as ThousandDataPoints<br />\| fields ThousandDataPoints|
|Data Volume|Ingest - LogsToMetricsRuleName|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="logstometricsrulename\_metrics\_volume" dataPoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as ThousandDataPoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| ThousandDataPoints / duration\_in\_min as %"DPM" <br />\| fields %"DPM"|
|Data Volume|Ingest - LogsToMetricsRuleName|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="logstometricsrulename\_metrics\_volume" dataPoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as ThousandDataPoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| ThousandDataPoints / duration\_in\_min as %"DPM" <br />\| fields %"DPM"|
|Data Volume|Ingest {{LogView}} - GB/Day|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| gbytes / duration\_in\_day as %"GB/Day"<br />\| fields %"GB/Day"|
|Data Volume|Ingest {{LogView}} - GB/Day|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| gbytes / duration\_in\_day as %"GB/Day"<br />\| fields %"GB/Day"|
|Data Volume|Ingest {{LogView}}- Log Volume|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes|
|Data Volume|Ingest {{LogView}}- Log Volume|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes|
|Data Volume|Ingest {{MetricsView}}- Data Points|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as ThousandDataPoints<br />\| fields ThousandDataPoints|
|Data Volume|Ingest {{MetricsView}}- Data Points|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as ThousandDataPoints<br />\| fields ThousandDataPoints|
|Data Volume|Ingest {{MetricsView}}- DPM|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume dataPoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as datapoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| fields %"DPM"|
|Data Volume|Ingest {{MetricsView}}- DPM|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume dataPoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as datapoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| fields %"DPM"|
|Data Volume|Ingest {{TracingView}}- Billed Bytes|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume <br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| sum(billedBytes) as %"billedBytes"<br />\| billedBytes/1Gi as BilledGBytes<br />\| fields BilledGBytes<br /><br /><br />|
|Data Volume|Ingest {{TracingView}}- Billed Bytes|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume <br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| sum(billedBytes) as %"billedBytes"<br />\| billedBytes/1Gi as BilledGBytes<br />\| fields BilledGBytes<br /><br /><br />|
|Data Volume|Ingest {{TracingView}}- Billed GBytes per min|Logs|Data Volume/Data Volume - Overview|<br />\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume <br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum(billedBytes) as %"billedBytes"<br />\| billedBytes/1Gi AS BilledGBytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| BilledGBytes / duration\_in\_min as %"Billed GBytes per min" <br />\| fields %"Billed GBytes per min" <br /><br />|
|Data Volume|Ingest {{TracingView}}- Billed GBytes per min|Logs|Installed Apps/Data Volume/Data Volume - Overview|<br />\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume <br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum(billedBytes) as %"billedBytes"<br />\| billedBytes/1Gi AS BilledGBytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| BilledGBytes / duration\_in\_min as %"Billed GBytes per min" <br />\| fields %"Billed GBytes per min" <br /><br />|
|Data Volume|Ingest by Collector|Logs|Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| timeslice 1h<br />\| sum(gbytes) as daily\_ingest\_gbytes by \_timeslice, collector<br />\| transpose row \_timeslice column collector|
|Data Volume|Ingest by Source Category|Logs|Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields|\_index=sumologic\_volume \_sourceCategory = "sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| timeslice 1h<br />\| sum(gbytes) as daily\_ingest\_gbytes by \_timeslice, sourceCategory<br />\| transpose row \_timeslice column sourceCategory|
|Data Volume|Ingest by Source Host|Logs|Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields|\_index=sumologic\_volume \_sourceCategory = "sourcehost\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourceHost, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| timeslice 1h<br />\| sum(gbytes) as daily\_ingest\_gbytes by \_timeslice, sourceHost<br />\| transpose row \_timeslice column sourceHost|
|Data Volume|Ingest DPM|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="collector\_metrics\_volume" dataPoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as ThousandDataPoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| ThousandDataPoints / duration\_in\_min as %"DPM" <br />\| fields %"DPM"|
|Data Volume|Ingest DPM|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="collector\_metrics\_volume" dataPoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| datapoints/1000 as ThousandDataPoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| ThousandDataPoints / duration\_in\_min as %"DPM" <br />\| fields %"DPM"|
|Data Volume|Ingest Outlier - {{MetricsView}}|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 6h<br />\| sum(datapoints) as datapoints by \_timeslice<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| outlier %"DPM"<br />|
|Data Volume|Ingest Outlier - {{MetricsView}}|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 6h<br />\| sum(datapoints) as datapoints by \_timeslice<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| outlier %"DPM"<br />|
|Data Volume|Ingest Outlier - {{TracingView}} by {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 6h<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice<br />\|outlier %"{{Unit}}"|
|Data Volume|Ingest Outlier - {{TracingView}} by {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 6h<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice<br />\|outlier %"{{Unit}}"|
|Data Volume|Ingest Prediction - {{MetricsView}}|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 6h<br />\| sum(datapoints) as datapoints by \_timeslice<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| predict  %"DPM"  by 1h model=ar, forecast=20<br />\| fillmissing timeslice(1h)<br />\| fields - datapoints, DPM\_error, duration\_in\_min|
|Data Volume|Ingest Prediction - {{MetricsView}}|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 6h<br />\| sum(datapoints) as datapoints by \_timeslice<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| predict  %"DPM"  by 1h model=ar, forecast=20<br />\| fillmissing timeslice(1h)<br />\| fields - datapoints, DPM\_error, duration\_in\_min|
|Data Volume|Ingest Prediction - {{TracingView}} by {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 1h<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice<br />\| predict %"{{Unit}}" by 1h model=ar, forecast=20<br />\| fillmissing timeslice(1h)<br />\| fields - {{Unit}}\_error|
|Data Volume|Ingest Prediction - {{TracingView}} by {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 1h<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice<br />\| predict %"{{Unit}}" by 1h model=ar, forecast=20<br />\| fillmissing timeslice(1h)<br />\| fields - {{Unit}}\_error|
|Data Volume|Ingest Predictions - {{Unit}} for Next Day|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory=sourcecategory\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 1m<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice<br />\| predict %"{{Unit}}" by 1m model=ar, forecast=1440<br />\| sum  ({{Unit}}\_predicted) as {{Unit}}\_predicted<br />\|if("{{Unit}}" matches "spansCount", 1000000, 1Gi) as denominator <br />\| {{Unit}}\_predicted/denominator as {{Unit}}\_predicted<br />\| fields - denominator|
|Data Volume|Ingest Predictions - {{Unit}} for Next Day|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory=sourcecategory\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 1m<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice<br />\| predict %"{{Unit}}" by 1m model=ar, forecast=1440<br />\| sum  ({{Unit}}\_predicted) as {{Unit}}\_predicted<br />\|if("{{Unit}}" matches "spansCount", 1000000, 1Gi) as denominator <br />\| {{Unit}}\_predicted/denominator as {{Unit}}\_predicted<br />\| fields - denominator|
|Data Volume|Ingest Spike  of Last {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="collector\_tracing\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 1h<br />\|sum({{Unit}}) as %"curr\_hrs\_{{Unit}}" by \_timeslice<br />\| sort by \_timeslice asc <br />\| diff %"curr\_hrs\_{{Unit}}"<br />\| where !isNull(\_diff)<br />\| (\_diff+%"curr\_hrs\_{{Unit}}") as %"prev\_hrs\_{{Unit}}"<br />\| ((\_diff / %"curr\_hrs\_{{Unit}}") \* 100) as pct\_incr<br />\| 50 as spikePercent<br />\| where (-1 \* pct\_incr) \> spikePercent<br />\| abs(pct\_incr) as pct\_incr<br />\| fields \_timeslice, %"curr\_hrs\_{{Unit}}", %"prev\_hrs\_{{Unit}}", pct\_incr|
|Data Volume|Ingest Spike  of Last {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="collector\_tracing\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 1h<br />\|sum({{Unit}}) as %"curr\_hrs\_{{Unit}}" by \_timeslice<br />\| sort by \_timeslice asc <br />\| diff %"curr\_hrs\_{{Unit}}"<br />\| where !isNull(\_diff)<br />\| (\_diff+%"curr\_hrs\_{{Unit}}") as %"prev\_hrs\_{{Unit}}"<br />\| ((\_diff / %"curr\_hrs\_{{Unit}}") \* 100) as pct\_incr<br />\| 50 as spikePercent<br />\| where (-1 \* pct\_incr) \> spikePercent<br />\| abs(pct\_incr) as pct\_incr<br />\| fields \_timeslice, %"curr\_hrs\_{{Unit}}", %"prev\_hrs\_{{Unit}}", pct\_incr|
|Data Volume|Ingest Spike (Last data point)|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1h<br />\| sum(gbytes) as curr\_hrs\_gbytes by \_timeslice<br />\| sort by \_timeslice asc <br />\| diff curr\_hrs\_gbytes<br />\| where !isNull(\_diff)<br />\| (\_diff+curr\_hrs\_gbytes) as prev\_hrs\_gbytes<br />\| ((\_diff / curr\_hrs\_gbytes) \* 100) as pct\_incr<br />\| 50 as spikePercent<br />\| where (-1 \* pct\_incr) \> spikePercent<br />\| abs(pct\_incr) as pct\_incr<br />\| fields \_timeslice, curr\_hrs\_gbytes, prev\_hrs\_gbytes, pct\_incr|
|Data Volume|Ingest Spike (Last data point)|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1h<br />\| sum(gbytes) as curr\_hrs\_gbytes by \_timeslice<br />\| sort by \_timeslice asc <br />\| diff curr\_hrs\_gbytes<br />\| where !isNull(\_diff)<br />\| (\_diff+curr\_hrs\_gbytes) as prev\_hrs\_gbytes<br />\| ((\_diff / curr\_hrs\_gbytes) \* 100) as pct\_incr<br />\| 50 as spikePercent<br />\| where (-1 \* pct\_incr) \> spikePercent<br />\| abs(pct\_incr) as pct\_incr<br />\| fields \_timeslice, curr\_hrs\_gbytes, prev\_hrs\_gbytes, pct\_incr|
|Data Volume|Ingest Spikes for Top 5 Collectors|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, collector<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, collector<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, collector, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Spikes for Top 5 Collectors|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, collector<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, collector<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, collector, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Spikes for Top 5 Source Categories|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourceCategory<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, sourceCategory<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, sourceCategory, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Spikes for Top 5 Source Categories|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourceCategory<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, sourceCategory<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, sourceCategory, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Spikes for Top 5 Source Hosts|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcehost\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcehost, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 6h<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourcehost<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, sourcehost<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, sourcehost, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Spikes for Top 5 Source Hosts|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcehost\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcehost, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 6h<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourcehost<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, sourcehost<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, sourcehost, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Spikes for Top 5 Source Names|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcename\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourceName, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourceName<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, sourceName<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, sourceName, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Spikes for Top 5 Source Names|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcename\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourceName, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourceName<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, sourceName<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, sourceName, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Spikes for Top 5 Sources|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "source\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as source, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, source<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, source<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, source, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Spikes for Top 5 Sources|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "source\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as source, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, source<br />\| compare with timeshift 1d<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, gbytes\_1d, source<br />\| if (!(isNull(gbytes\_1d)), ((gbytes - gbytes\_1d) / gbytes\_1d) \* 100, gbytes \* 100) as percent\_diff<br />\| if (isNull(gbytes\_1d), 0, gbytes\_1d) as gbytes\_1d<br />\| where percent\_diff \> 0<br />\| sort percent\_diff<br />\| limit 5<br />\| fields \_timeslice, source, gbytes, gbytes\_1d,percent\_diff|
|Data Volume|Ingest Today Vs Yesterday - {{MetricsView}}|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume  \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 6h<br />\| sum(datapoints) as daily\_ingest\_datapoints by \_timeslice<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| daily\_ingest\_datapoints / duration\_in\_min as %"DPM" <br />\| compare timeshift 1d<br />\| fields - daily\_ingest\_datapoints, daily\_ingest\_datapoints\_1d, duration\_in\_min, duration\_in\_min\_1d<br />|
|Data Volume|Ingest Today Vs Yesterday - {{MetricsView}}|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume  \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 6h<br />\| sum(datapoints) as daily\_ingest\_datapoints by \_timeslice<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| daily\_ingest\_datapoints / duration\_in\_min as %"DPM" <br />\| compare timeshift 1d<br />\| fields - daily\_ingest\_datapoints, daily\_ingest\_datapoints\_1d, duration\_in\_min, duration\_in\_min\_1d<br />|
|Data Volume|Ingest Today vs Yesterday - {{TracingView}}  by {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 5m<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice<br />\| compare timeshift 1d|
|Data Volume|Ingest Today vs Yesterday - {{TracingView}}  by {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 5m<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice<br />\| compare timeshift 1d|
|Data Volume|Ingest Trend - {{MetricsView}}|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 1d<br />\| sum(datapoints) as datapoints by \_timeslice<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| fields - datapoints, duration\_in\_min <br />|
|Data Volume|Ingest Trend - {{MetricsView}}|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 1d<br />\| sum(datapoints) as datapoints by \_timeslice<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| fields - datapoints, duration\_in\_min <br />|
|Data Volume|Ingest Trend - {{TracingView}}|Logs|Data Volume/Data Volume - Tracing|<br />\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<field\_type\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 1d<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice, field\_type<br />\| %"{{Unit}}"  as %"{{Unit}} Count"<br />\| fields -%"{{Unit}}"<br />\| transpose row \_timeslice column field\_type|
|Data Volume|Ingest Trend - {{TracingView}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|<br />\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<field\_type\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| timeslice 1d<br />\|sum({{Unit}}) as %"{{Unit}}" by \_timeslice, field\_type<br />\| %"{{Unit}}"  as %"{{Unit}} Count"<br />\| fields -%"{{Unit}}"<br />\| transpose row \_timeslice column field\_type|
|Data Volume|Log Ingest Capacity Utilization|Logs|Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume \_sourcecategory="collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as ingest\_gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| ingest\_gbytes / duration\_in\_day as %"AvgLogIngestPerDay"<br />\| {{Daily\_Log\_Ingest\_Capacity}} as %"DailyLogIngestCapacity" // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| (%"AvgLogIngestPerDay"/%"DailyLogIngestCapacity")\*100 as %"LogIngest\_Capacity\_Utilization"<br />\| fields %"LogIngest\_Capacity\_Utilization"|
|Data Volume|Log Ingest Capacity Utilization|Logs|Installed Apps/Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume \_sourcecategory="collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as ingest\_gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| ingest\_gbytes / duration\_in\_day as %"AvgLogIngestPerDay"<br />\| {{Daily\_Log\_Ingest\_Capacity}} as %"DailyLogIngestCapacity" // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| (%"AvgLogIngestPerDay"/%"DailyLogIngestCapacity")\*100 as %"LogIngest\_Capacity\_Utilization"<br />\| fields %"LogIngest\_Capacity\_Utilization"|
|Data Volume|Metrics Ingestion|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| datapoints/1000/1440 as datapoints <br />\| sum(dataPoints) as dataPoints <br />\| dataPoints\*{{MetricsBurndownRate}} as credits <br />\|fields -dataPoints|
|Data Volume|Predicted Ingest Tomorrow|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1d<br />\| sum(gbytes) as gbytes by \_timeslice<br />\| predict gbytes by 1d model=ar, forecast=48h<br />\| fields gbytes\_predicted, \_timeslice<br />\| last(gbytes\_predicted)|
|Data Volume|Predicted Ingest Tomorrow|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 1m<br />\| sum(datapoints) as datapoints by  \_timeslice<br />\| predict datapoints by 1m model=ar, forecast=1440m <br />\| sum (datapoints\_predicted) as datapoints\_predicted<br />//\| datapoints\_predicted/1000 as datapoints\_predicted<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints\_predicted / duration\_in\_min as %"DPM" <br />\| fields %"DPM"|
|Data Volume|Predicted Ingest Tomorrow|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| timeslice 1d<br />\| sum(gbytes) as gbytes by \_timeslice<br />\| predict gbytes by 1d model=ar, forecast=48h<br />\| fields gbytes\_predicted, \_timeslice<br />\| last(gbytes\_predicted)|
|Data Volume|Predicted Ingest Tomorrow|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| timeslice 1m<br />\| sum(datapoints) as datapoints by  \_timeslice<br />\| predict datapoints by 1m model=ar, forecast=1440m <br />\| sum (datapoints\_predicted) as datapoints\_predicted<br />//\| datapoints\_predicted/1000 as datapoints\_predicted<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints\_predicted / duration\_in\_min as %"DPM" <br />\| fields %"DPM"|
|Data Volume|Source Category (1-30%) Vol|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory="sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by sourcecategory<br />\| round(gbytes,2) as gbytes<br />\| total gbytes as tot\_gbytes <br />\| round(tot\_gbytes,2) as tot\_gbytes<br />\| (gbytes\*100/tot\_gbytes) as pct\_total <br />\| round(pct\_total,2) as pct\_total <br />\| where pct\_total \>= 1 and pct\_total \<= 30 // candidates for partition<br />\| sort pct\_total|
|Data Volume|Source Category (1-30%) Vol|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory="sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by sourcecategory<br />\| round(gbytes,2) as gbytes<br />\| total gbytes as tot\_gbytes <br />\| round(tot\_gbytes,2) as tot\_gbytes<br />\| (gbytes\*100/tot\_gbytes) as pct\_total <br />\| round(pct\_total,2) as pct\_total <br />\| where pct\_total \>= 1 and pct\_total \<= 30 // candidates for partition<br />\| sort pct\_total|
|Data Volume|Source Category (30%+) Vol|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume  \_sourceCategory = "sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| sum(gbytes) as gbytes by sourcecategory<br />\| round(gbytes,2) as gbytes<br />\| total gbytes as tot\_gbytes <br />\| round(tot\_gbytes,2) as tot\_gbytes<br />\| (gbytes\*100/tot\_gbytes) as pct\_total <br />\| round(pct\_total,2) as pct\_total<br />\| 30 as threshold<br />\| where pct\_total \> threshold<br />\| sort pct\_total|
|Data Volume|Source Category (30%+) Vol|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume  \_sourceCategory = "sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes<br />\| sum(gbytes) as gbytes by sourcecategory<br />\| round(gbytes,2) as gbytes<br />\| total gbytes as tot\_gbytes <br />\| round(tot\_gbytes,2) as tot\_gbytes<br />\| (gbytes\*100/tot\_gbytes) as pct\_total <br />\| round(pct\_total,2) as pct\_total<br />\| 30 as threshold<br />\| where pct\_total \> threshold<br />\| sort pct\_total|
|Data Volume|Subscribed DPM Ingest Capacity|Logs|Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as dpm <br />\| {{Metric\_DPM\_Ingest\_Capacity}} as %"DPM\_Capacity" // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| fields -datapoints, duration\_in\_min, dpm|
|Data Volume|Subscribed DPM Ingest Capacity|Logs|Installed Apps/Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume dataPoints \_sourceCategory="collector\_metrics\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as dpm <br />\| {{Metric\_DPM\_Ingest\_Capacity}} as %"DPM\_Capacity" // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| fields -datapoints, duration\_in\_min, dpm|
|Data Volume|Subscribed Log Ingest Capacity|Logs|Installed Apps/Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume \_sourcecategory="collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as ingest\_gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| ingest\_gbytes / duration\_in\_day as %"AvgLogIngestPerDay"<br />\| {{Daily\_Log\_Ingest\_Capacity}} as %"DailyLogIngestCapacity" // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| fields %"DailyLogIngestCapacity"|
|Data Volume|Subscribed Log Ingest Capacity|Logs|Data Volume/Data Volume - Capacity Utilization|\_index=sumologic\_volume \_sourcecategory="collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\| where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as ingest\_gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| ingest\_gbytes / duration\_in\_day as %"AvgLogIngestPerDay"<br />\| {{Daily\_Log\_Ingest\_Capacity}} as %"DailyLogIngestCapacity" // This is account contract based value. Customize this value. Can be found in Administration \> Account \> Account Overview<br />\| fields %"DailyLogIngestCapacity"|
|Data Volume|Top 10 {{LogView}} by Credits used in Continuous Tier|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes" as sourceCategory, dataTier, bytes<br />\| where dataTier matches "Continuous"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by sourceCategory<br />\| gbytes\*{{ContinuousTierBurndownRate}} as credits <br />\|fields -gbytes<br />\| top 10 sourceCategory by credits<br />|
|Data Volume|Top 10 {{LogView}} by Credits used in CSE Tier|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes" as sourceCategory, dataTier, bytes<br />\| where  dataTier matches "CSE"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by sourceCategory<br />\| gbytes\*{{CSETierBurndownRate}} as credits <br />\|fields -gbytes<br />\| top 10 sourceCategory by credits<br />|
|Data Volume|Top 10 {{LogView}} by Credits used in Frequent Tier|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes" as sourceCategory, dataTier, bytes<br />\| where  dataTier matches "Frequent"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by sourceCategory<br />\| gbytes\*{{FrequentTierBurndownRate}} as credits <br />\|fields -gbytes<br />\| top 10 sourceCategory by credits<br />|
|Data Volume|Top 10 {{LogView}} by Credits used in Infrequent Tier|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes" as sourceCategory, dataTier, bytes<br />\| where  dataTier matches "Infrequent"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by sourceCategory<br />\| gbytes\*{{InfrequentTierBurndownRate}} as credits <br />\|fields -gbytes<br />\| top 10 sourceCategory by credits<br />|
|Data Volume|Top 10 {{MetricsView}} by Credits used in Metrics Ingestion|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume<br />\| parse regex "\\"(?\<sourceCategory\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| datapoints/1000/1440 as datapoints <br />\| sum(dataPoints) as dataPoints by sourceCategory<br />\| dataPoints\*{{MetricsBurndownRate}} as credits <br />\|fields -dataPoints<br />\| top 10 sourceCategory by credits|
|Data Volume|Top 10 {{TracingView}} by Credits used in Tracing Ingestion|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume<br />\| parse regex "\\"(?\<sourceCategory\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\| billedBytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by sourceCategory<br />\| gbytes\*{{TracingBurndownRate}} as credits <br />\| fields -gbytes<br />\| top 10 sourceCategory by credits|
|Data Volume|Top 5  {{LogView}}|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes \| sum(gbytes) as gbytes by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| gbytes / duration\_in\_day as %"GB/Day"<br />\| top 5 collector by %"GB/Day"|
|Data Volume|Top 5  {{LogView}}|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes \| sum(gbytes) as gbytes by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| gbytes / duration\_in\_day as %"GB/Day"<br />\| top 5 collector by %"GB/Day"|
|Data Volume|Top 5 {{MetricsView}}|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 collector by %"DPM"|
|Data Volume|Top 5 {{MetricsView}}|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 collector by %"DPM"|
|Data Volume|Top 5 {{TracingView}} by Billed Bytes|Logs|Installed Apps/Data Volume/Data Volume - Overview|<br />\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume <br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum(billedBytes) as billedBytes by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| billedBytes / duration\_in\_min as % "billedBytes per minute"<br />\| top 5 collector by % "billedBytes per minute"|
|Data Volume|Top 5 {{TracingView}} by Billed Bytes|Logs|Data Volume/Data Volume - Overview|<br />\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume <br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum(billedBytes) as billedBytes by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| billedBytes / duration\_in\_min as % "billedBytes per minute"<br />\| top 5 collector by % "billedBytes per minute"|
|Data Volume|Top 5 Collectors|Logs|Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume" <br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by collector<br />\| round(gbytes,2) as gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| gbytes / duration\_in\_day as %"GB/Day"<br />\| round(%"GB/Day",2) as %"GB/Day"<br />\| top 5 collector by gbytes, %"GB/Day"|
|Data Volume|Top 5 Collectors|Logs|Data Volume/Data Volume - Log Spikes|<br />\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, collector<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, collector<br />\| transpose row \_timeslice column collector|
|Data Volume|Top 5 Collectors|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="collector\_metrics\_volume" datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 collector by %"DPM"|
|Data Volume|Top 5 Collectors|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|<br />\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, collector<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, collector<br />\| transpose row \_timeslice column collector|
|Data Volume|Top 5 Collectors|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="collector\_metrics\_volume" datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 collector by %"DPM"|
|Data Volume|Top 5 Collectors by {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="collector\_tracing\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "Billion {{Unit}} per minute"<br />\| top 5 collector by % "Billion {{Unit}} per minute"|
|Data Volume|Top 5 Collectors by {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="collector\_tracing\_volume"<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by collector<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "Billion {{Unit}} per minute"<br />\| top 5 collector by % "Billion {{Unit}} per minute"|
|Data Volume|Top 5 Indexes (Non-Default)|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory="view\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as index, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| where index not in ("Default Index", "sumologic\_volume", "sumologic\_audit")<br />\| bytes/1Gi as gbytes<br />\| sum(gbytes) as gbytes by index<br />\| top 5 index by gbytes|
|Data Volume|Top 5 Indexes (Non-Default)|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory="view\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as index, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| where index not in ("Default Index", "sumologic\_volume", "sumologic\_audit")<br />\| bytes/1Gi as gbytes<br />\| sum(gbytes) as gbytes by index<br />\| top 5 index by gbytes|
|Data Volume|Top 5 Service by {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="service\_tracing\_volume"<br />\| parse regex "\\"(?\<source\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by source<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "{{Unit}} per minute"<br />\| top 5 source by % "{{Unit}} per minute"|
|Data Volume|Top 5 Service by {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="service\_tracing\_volume"<br />\| parse regex "\\"(?\<source\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by source<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "{{Unit}} per minute"<br />\| top 5 source by % "{{Unit}} per minute"|
|Data Volume|Top 5 Source Categories|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="sourcecategory\_metrics\_volume" datapoints<br />\| parse regex "\\"(?\<sourcecategory\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by sourcecategory<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 sourcecategory by %"DPM"|
|Data Volume|Top 5 Source Categories|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="sourcecategory\_metrics\_volume" datapoints<br />\| parse regex "\\"(?\<sourcecategory\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by sourcecategory<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 sourcecategory by %"DPM"|
|Data Volume|Top 5 Source Categories|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourceCategory<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, sourceCategory<br />\| transpose row \_timeslice column sourceCategory|
|Data Volume|Top 5 Source Categories|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourceCategory<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, sourceCategory<br />\| transpose row \_timeslice column sourceCategory|
|Data Volume|Top 5 Source Categories|Logs|Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields|\_index=sumologic\_volume \_sourceCategory = "sourcecategory\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcecategory, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by sourceCategory<br />\| round(gbytes,2) as gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| gbytes / duration\_in\_day as %"GB/Day"<br />\| round(%"GB/Day",2) as %"GB/Day"<br />\| top 5 sourceCategory by gbytes, %"GB/Day"|
|Data Volume|Top 5 Source Categories by {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="sourcecategory\_tracing\_volume"<br />\| parse regex "\\"(?\<sourcecategory\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by sourcecategory<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "Billion {{Unit}} per minute"<br />\| top 5 sourcecategory by % "Billion {{Unit}} per minute"|
|Data Volume|Top 5 Source Categories by {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="sourcecategory\_tracing\_volume"<br />\| parse regex "\\"(?\<sourcecategory\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by sourcecategory<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "Billion {{Unit}} per minute"<br />\| top 5 sourcecategory by % "Billion {{Unit}} per minute"|
|Data Volume|Top 5 Source Hosts|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="sourcehost\_metrics\_volume" datapoints<br />\| parse regex "\\"(?\<sourcehost\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| where sourcehost !="Unknown"<br />\| sum(datapoints) as datapoints by sourcehost<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 sourcehost by %"DPM"|
|Data Volume|Top 5 Source Hosts|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="sourcehost\_metrics\_volume" datapoints<br />\| parse regex "\\"(?\<sourcehost\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| where sourcehost !="Unknown"<br />\| sum(datapoints) as datapoints by sourcehost<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 sourcehost by %"DPM"|
|Data Volume|Top 5 Source Hosts|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcehost\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcehost, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourcehost<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, sourcehost<br />\| transpose row \_timeslice column sourcehost|
|Data Volume|Top 5 Source Hosts|Logs|Installed Apps/Data Volume/Data Volume - Logs by Metadata Fields|\_index=sumologic\_volume \_sourceCategory = "sourcehost\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourceHost, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by sourceHost<br />\| round(gbytes,2) as gbytes<br />\| ((queryEndTime() - queryStartTime())/(1000\*60\*60\*24)) as duration\_in\_day<br />\| gbytes / duration\_in\_day as %"GB/Day"<br />\| round(%"GB/Day",2) as %"GB/Day"<br />\| top 5 sourceHost by gbytes, %"GB/Day"|
|Data Volume|Top 5 Source Hosts|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcehost\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcehost, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourcehost<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, sourcehost<br />\| transpose row \_timeslice column sourcehost|
|Data Volume|Top 5 source Hosts by {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="sourcehost\_tracing\_volume"<br />\| parse regex "\\"(?\<sourceHost\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by sourceHost<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "{{Unit}} per minute"<br />\| top 5 sourceHost by % "{{Unit}} per minute"|
|Data Volume|Top 5 source Hosts by {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="sourcehost\_tracing\_volume"<br />\| parse regex "\\"(?\<sourceHost\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by sourceHost<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "{{Unit}} per minute"<br />\| top 5 sourceHost by % "{{Unit}} per minute"|
|Data Volume|Top 5 source Name by {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="sourcename\_tracing\_volume"<br />\| parse regex "\\"(?\<sourceName\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by sourceName<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "{{Unit}} per minute"<br />\| top 5 sourceName by % "{{Unit}} per minute"|
|Data Volume|Top 5 source Name by {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="sourcename\_tracing\_volume"<br />\| parse regex "\\"(?\<sourceName\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by sourceName<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "{{Unit}} per minute"<br />\| top 5 sourceName by % "{{Unit}} per minute"|
|Data Volume|Top 5 Source Names|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcename\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcename, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourcename<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, sourcename<br />\| transpose row \_timeslice column sourcename|
|Data Volume|Top 5 Source Names|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "sourcename\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as sourcename, dataTier, bytes, count<br />\|where dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, sourcename<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, sourcename<br />\| transpose row \_timeslice column sourcename|
|Data Volume|Top 5 Sources|Logs|Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="source\_metrics\_volume" datapoints<br />\| parse regex "\\"(?\<source\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by source<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 source by %"DPM"|
|Data Volume|Top 5 Sources|Logs|Installed Apps/Data Volume/Data Volume - Metrics|\_index=sumologic\_volume \_sourceCategory="source\_metrics\_volume" datapoints<br />\| parse regex "\\"(?\<source\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by source<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| datapoints / duration\_in\_min as %"DPM" <br />\| top 5 source by %"DPM"|
|Data Volume|Top 5 Sources|Logs|Installed Apps/Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "source\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as source, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, source<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, source<br />\| transpose row \_timeslice column source|
|Data Volume|Top 5 Sources|Logs|Data Volume/Data Volume - Log Spikes|\_index=sumologic\_volume \_sourceCategory = "source\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as source, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| timeslice 1d<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes by \_timeslice, source<br />\| sort \_timeslice desc, gbytes desc<br />\| 1 as rownum<br />\| accum rownum by \_timeslice<br />\| where \_accum \<= 5 // limit by this<br />\| fields \_timeslice, gbytes, source<br />\| transpose row \_timeslice column source|
|Data Volume|Top 5 Sources by {{Unit}}|Logs|Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="source\_tracing\_volume"<br />\| parse regex "\\"(?\<source\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by source<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "{{Unit}} per minute"<br />\| top 5 source by % "{{Unit}} per minute"|
|Data Volume|Top 5 Sources by {{Unit}}|Logs|Installed Apps/Data Volume/Data Volume - Tracing|\_index=sumologic\_volume \_sourceCategory="source\_tracing\_volume"<br />\| parse regex "\\"(?\<source\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum({{Unit}}) as %"{{Unit}}" by source<br />\| ((queryEndTime() - queryStartTime())/(1000\*60)) as duration\_in\_min<br />\| %"{{Unit}}" / duration\_in\_min as % "{{Unit}} per minute"<br />\| top 5 source by % "{{Unit}} per minute"|
|Data Volume|Top Sources  (Other \< {{other\_pct}}%)|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourceCategory="{{LogView}}\_and\_tier\_volume"<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as value, dataTier, bytes, count<br /><br />\| sum(count) as events,sum(bytes) as bytes by datatier,value,\_sourceCategory<br />\| bytes /1Gi as gb \| sort gb<br />\| parse field=\_sourcecategory "\*\_and\_tier\_volume" as dimension <br />\| fields -\_sourcecategory,bytes<br /><br />\| if (length(value) \> 50,concat(substring(value,0,50),"..."),value) as value <br />\| sum(events) as events,sum(gb) as gbytes by dimension,value,dataTier<br />\| total gbytes as tgb <br />\| total gbytes as tgbs by value<br />\| tgbs / tgb as fraction<br /><br />// \*\*\* THIS LINE rolls up small sources into 'other' \*\*\*<br />\| if(( fraction \* 100 )\> {{other\_pct}},value,"other" ) as value<br />\| fraction \* 100 as percent<br />\| if (datatier="Frequent",gbytes \* {{FrequentTierBurndownRate}},if(datatier="Infrequent",gbytes \* {{InfrequentTierBurndownRate}},if(datatier="Continuous",gbytes \* {{ContinuousTierBurndownRate}},gbytes \* {{CSETierBurndownRate}}))) as credits<br />\|sum(credits) as credits,count as rows, sum(events) as events,sum(gbytes) as gbytes, sum(percent) as percent by datatier,dimension,value<br />\| sort percent|
|Data Volume|Total Data Ingested|Logs|Installed Apps/Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume" <br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as daily\_ingest\_gbytes|
|Data Volume|Total Data Ingested|Logs|Data Volume/Data Volume - Logs|\_index=sumologic\_volume \_sourceCategory = "collector\_and\_tier\_volume" <br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\|where  dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes <br />\| sum(gbytes) as daily\_ingest\_gbytes|
|Data Volume|Tracing Ingestion by BilledBytes|Logs|Data Volume/Data Volume - Credits|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume <br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum(billedBytes) as billedBytes<br />\| billedBytes/1Gi as gbytes <br />\| sum(gbytes) as gbytes <br />\| gbytes\*{{TracingBurndownRate}} as credits <br />\|fields -gbytes|
|Data Volume|Usage Percentage of {{LogView}} by Tier|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\| bytes/1Gi as gbytes \| sum(gbytes) as gbytes by dataTier<br />|
|Data Volume|Usage Percentage of {{LogView}} by Tier|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\| bytes/1Gi as gbytes \| sum(gbytes) as gbytes by dataTier<br />|
|Data Volume|Usage Percentage of {{LogView}} by Tier({{Tier}})|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes \| sum(gbytes) as gbytes by collector<br />|
|Data Volume|Usage Percentage of {{LogView}} by Tier({{Tier}})|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{LogView}}\_and\_tier\_volume<br />\| parse regex "(?\<data\>\\{[^\\{]+\\})" multi<br />\| json field=data "field","dataTier","sizeInBytes","count" as collector, dataTier, bytes, count<br />\| where dataTier matches "{{Tier}}"<br />\| bytes/1Gi as gbytes \| sum(gbytes) as gbytes by collector<br />|
|Data Volume|Usage Percentage of {{MetricsView}}|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by collector<br />|
|Data Volume|Usage Percentage of {{MetricsView}}|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{MetricsView}}\_metrics\_volume datapoints<br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"dataPoints\\"\\:(?\<datapoints\>\\d+)\\}" multi<br />\| sum(datapoints) as datapoints by collector<br />|
|Data Volume|Usage Percentage of {{TracingView}}|Logs|Installed Apps/Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume <br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum(billedBytes) as billedBytes by collector|
|Data Volume|Usage Percentage of {{TracingView}}|Logs|Data Volume/Data Volume - Overview|\_index=sumologic\_volume \_sourcecategory={{TracingView}}\_tracing\_volume <br />\| parse regex "\\"(?\<collector\>[^\\"]+)\\"\\:\\{\\"billedBytes\\"\\:(?\<billedBytes\>\\d+)\\,\\"spansCount\\"\\:(?\<spansCount\>\\d+)\\}" multi<br />\|sum(billedBytes) as billedBytes by collector|

